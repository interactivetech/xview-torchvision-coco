{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+\n",
      "| categoy | AP50 |\n",
      "+---------+------+\n",
      "| cat     | 0.01 |\n",
      "| dog     | 0.02 |\n",
      "| mouse   | nan  |\n",
      "+---------+------+\n"
     ]
    }
   ],
   "source": [
    "from terminaltables import AsciiTable\n",
    "\n",
    "table_data = [\n",
    "    ['categoy', 'AP50']]\n",
    "table_data+=    [('cat', '0.01'),\n",
    "    ('dog', '0.02'),\n",
    "    ('mouse', 'nan')]\n",
    "table = AsciiTable(table_data)\n",
    "print(table.table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TORCHVISION_VERSION:  0.13.1+cu102 /opt/conda/lib/python3.8/site-packages/torchvision/__init__.py\n",
      "TORCH_VERSION:  1.12.1+cu102 /opt/conda/lib/python3.8/site-packages/torch/__init__.py\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import torch\n",
    "from utils.data import build_dataset,build_xview_dataset, unwrap_collate_fn\n",
    "from attrdict import AttrDict\n",
    "from utils.group_by_aspect_ratio import create_aspect_ratio_groups, GroupedBatchSampler\n",
    "from utils.fcos import fcos_resnet50_fpn\n",
    "# from torchvision.models.detection import fcos_resnet50_fpn\n",
    "from torchvision.models.detection import ssd300_vgg16\n",
    "\n",
    "import datetime\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils.engine import train_and_eval,eval_model\n",
    "import torchvision\n",
    "from pycocotools import mask as coco_mask\n",
    "from pycocotools.coco import COCO\n",
    "import math\n",
    "from lr_schedulers import WarmupWrapper\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "\n",
    "from utils.model import make_custom_object_detection_model_fcos, build_frcnn_model\n",
    "import matplotlib.pyplot as plt\n",
    "from train import load_dataset\n",
    "import numpy as np\n",
    "\n",
    "from determined.experimental import Determined\n",
    "\n",
    "# remove warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up .detignore file so the checkpoints directory is not packaged into future experiments\n",
    "!echo checkpoints > .detignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/determined-ai/determined/master/determined-logo.png\" align='right' width=150 />\n",
    "\n",
    "# Building a Geospatial Detection Model with Determined\n",
    "\n",
    "<img src=\"https://www.cis.upenn.edu/~jshi/ped_html/images/PennPed00071_1.png\" width=400 />\n",
    "\n",
    "\n",
    "This notebook will walk through the benefits of building a Deep Learning model with Determined.  We will build an object detection model trained on the [Penn-Fudan Database for Pedestrian Detection and Segmentation](https://www.cis.upenn.edu/~jshi/ped_html/).\n",
    "\n",
    "\n",
    "# Table of Contents\n",
    "\n",
    "\n",
    "<font size=\"3\">\n",
    "<ol>\n",
    "  <li>What Modeling looks like Today</li>\n",
    "  <li>Building a model with Determined\n",
    "    <ol>\n",
    "      <li>Single GPU training</li>\n",
    "      <li>Cluster-scale multi-GPU training</li>\n",
    "      <li>Adapative hyperparameter search</li>\n",
    "    </ol>\n",
    "  </li>\n",
    "</ol>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What modeling looks like without Determined\n",
    "\n",
    "<font size=\"4\">First let's look at the kind of work modelers do today.  Below, we train a model we found on Github and modified, printing validation set metrics after each epoch.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "PATHS:  {'train': ('determined-ai-xview-coco-dataset/train_sliced_no_neg/train_images_300_02/', '/tmp/train_sliced_no_neg/train_300_02_1k.json'), 'val': ('determined-ai-xview-coco-dataset/train_sliced_no_neg/train_images_300_02/', '/tmp/val_sliced_no_neg/val_300_02_1k.json')}\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "self.catIdtoCls:  {0: 1, 1: 2, 2: 3, 3: 4, 4: 5, 5: 6, 6: 7, 7: 8, 8: 9, 9: 10, 10: 11, 11: 12, 12: 13, 13: 14, 14: 15, 15: 16, 16: 17, 17: 18, 18: 19, 19: 20, 20: 21, 21: 22, 22: 23, 23: 24, 24: 25, 25: 26, 26: 27, 27: 28, 28: 29, 29: 30, 30: 31, 31: 32, 32: 33, 33: 34, 34: 35, 35: 36, 36: 37, 37: 38, 38: 39, 39: 40, 40: 41, 41: 42, 42: 43, 43: 44, 44: 45, 45: 46, 46: 47, 47: 48, 48: 49, 49: 50, 50: 51, 51: 52, 52: 53, 53: 54, 54: 55, 55: 56, 56: 57, 57: 58, 58: 59, 59: 60}\n",
      "--num_classes:  61\n",
      "PATHS:  {'train': ('determined-ai-xview-coco-dataset/val_sliced_no_neg/val_images_300_02/', '/tmp/train_sliced_no_neg/train_300_02_1k.json'), 'val': ('determined-ai-xview-coco-dataset/val_sliced_no_neg/val_images_300_02/', '/tmp/val_sliced_no_neg/val_300_02_1k.json')}\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "self.catIdtoCls:  {0: 1, 1: 2, 2: 3, 3: 4, 4: 5, 5: 6, 6: 7, 7: 8, 8: 9, 9: 10, 10: 11, 11: 12, 12: 13, 13: 14, 14: 15, 15: 16, 16: 17, 17: 18, 18: 19, 19: 20, 20: 21, 21: 22, 22: 23, 23: 24, 24: 25, 25: 26, 26: 27, 27: 28, 28: 29, 29: 30, 30: 31, 31: 32, 32: 33, 33: 34, 34: 35, 35: 36, 36: 37, 37: 38, 38: 39, 39: 40, 40: 41, 41: 42, 42: 43, 43: 44, 44: 45, 45: 46, 46: 47, 47: 48, 48: 49, 49: 50, 50: 51, 51: 52, 52: 53, 53: 54, 54: 55, 55: 56, 56: 57, 57: 58, 58: 59, 59: 60}\n",
      "Creating data loaders\n",
      "Create Model\n"
     ]
    }
   ],
   "source": [
    "DEVICE='cuda'\n",
    "#Data loading code\n",
    "device = torch.device(DEVICE)\n",
    "cpu_device = torch.device(DEVICE)\n",
    "print(\"Loading data\")\n",
    "TRAIN_DATA_DIR='determined-ai-xview-coco-dataset/train_sliced_no_neg/train_images_300_02/'\n",
    "VAL_DATA_DIR='determined-ai-xview-coco-dataset/val_sliced_no_neg/val_images_300_02/'\n",
    "\n",
    "dataset, num_classes, dataset_test,data_loader, data_loader_test= load_dataset(TRAIN_DATA_DIR=TRAIN_DATA_DIR,VAL_DATA_DIR=VAL_DATA_DIR,train_batch_size=8,test_batch_size=8)\n",
    "print(\"Create Model\")\n",
    "model = build_frcnn_model(dataset.num_classes)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(\n",
    "        model.parameters(),\n",
    "        lr=0.01,\n",
    "        momentum=0.9,\n",
    "        weight_decay=1e-4,\n",
    "        nesterov=\"nesterov\",\n",
    "    )\n",
    "\n",
    "scheduler_cls = WarmupWrapper(MultiStepLR)\n",
    "scheduler = scheduler_cls(\n",
    "    'linear',  # warmup schedule\n",
    "    100,  # warmup_iters\n",
    "    0.001,  # warmup_ratio\n",
    "    optimizer,\n",
    "    [177429, 236572],  # milestones\n",
    "    0.1,  # gamma\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "Epochs: 2\n",
      "Epoch #: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [08:15<00:00,  3.96s/it, loss=['loss: 0.027', 'loss_classifier: 0.016', 'loss_box_reg: 0.008', 'loss_objectness: 0.002', 'loss_rpn_box_reg: 0.000']]\n",
      "100%|██████████| 125/125 [03:43<00:00,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.231\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.802\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.161\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.231\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.260\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.380\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.380\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.380\n",
      "~~~~ Mean and per-category AP @ IoU=[0.50,0.50] ~~~~\n",
      "80.2\n",
      "Per Class AP:\n",
      "\n",
      "+------------------------+----------+\n",
      "| category               | AP       |\n",
      "+------------------------+----------+\n",
      "| Fixed-wing Aircraft    | nan      |\n",
      "| Small Aircraft         | nan      |\n",
      "| Cargo Plane            | 0.230752 |\n",
      "| Helicopter             | nan      |\n",
      "| Passenger Vehicle      | nan      |\n",
      "| Small Car              | nan      |\n",
      "| Bus                    | nan      |\n",
      "| Pickup Truck           | nan      |\n",
      "| Utility Truck          | nan      |\n",
      "| Truck                  | nan      |\n",
      "| Cargo Truck            | nan      |\n",
      "| Truck w/Box            | nan      |\n",
      "| Truck Tractor          | nan      |\n",
      "| Trailer                | nan      |\n",
      "| Truck w/Flatbed        | nan      |\n",
      "| Truck w/Liquid         | nan      |\n",
      "| Crane Truck            | nan      |\n",
      "| Railway Vehicle        | nan      |\n",
      "| Passenger Car          | nan      |\n",
      "| Cargo Car              | nan      |\n",
      "| Flat Car               | nan      |\n",
      "| Tank car               | nan      |\n",
      "| Locomotive             | nan      |\n",
      "| Maritime Vessel        | nan      |\n",
      "| Motorboat              | nan      |\n",
      "| Sailboat               | nan      |\n",
      "| Tugboat                | nan      |\n",
      "| Barge                  | nan      |\n",
      "| Fishing Vessel         | nan      |\n",
      "| Ferry                  | nan      |\n",
      "| Yacht                  | nan      |\n",
      "| Container Ship         | nan      |\n",
      "| Oil Tanker             | nan      |\n",
      "| Engineering Vehicle    | nan      |\n",
      "| Tower crane            | nan      |\n",
      "| Container Crane        | nan      |\n",
      "| Reach Stacker          | nan      |\n",
      "| Straddle Carrier       | nan      |\n",
      "| Mobile Crane           | nan      |\n",
      "| Dump Truck             | nan      |\n",
      "| Haul Truck             | nan      |\n",
      "| Scraper/Tractor        | nan      |\n",
      "| Front loader/Bulldozer | nan      |\n",
      "| Excavator              | nan      |\n",
      "| Cement Mixer           | nan      |\n",
      "| Ground Grader          | nan      |\n",
      "| Hut/Tent               | nan      |\n",
      "| Shed                   | nan      |\n",
      "| Building               | nan      |\n",
      "| Aircraft Hangar        | nan      |\n",
      "| Damaged Building       | nan      |\n",
      "| Facility               | nan      |\n",
      "| Construction Site      | nan      |\n",
      "| Vehicle Lot            | nan      |\n",
      "| Helipad                | nan      |\n",
      "| Storage Tank           | nan      |\n",
      "| Shipping container lot | nan      |\n",
      "| Shipping Container     | nan      |\n",
      "| Pylon                  | nan      |\n",
      "| Tower                  | nan      |\n",
      "+------------------------+----------+\n",
      "mean coco AP:  0.230752\n",
      "\n",
      "+------------------------+----------+\n",
      "| category               | AP@50    |\n",
      "+------------------------+----------+\n",
      "| Fixed-wing Aircraft    | nan      |\n",
      "| Small Aircraft         | nan      |\n",
      "| Cargo Plane            | nan      |\n",
      "| Helicopter             | 0.801980 |\n",
      "| Passenger Vehicle      | nan      |\n",
      "| Small Car              | nan      |\n",
      "| Bus                    | nan      |\n",
      "| Pickup Truck           | nan      |\n",
      "| Utility Truck          | nan      |\n",
      "| Truck                  | nan      |\n",
      "| Cargo Truck            | nan      |\n",
      "| Truck w/Box            | nan      |\n",
      "| Truck Tractor          | nan      |\n",
      "| Trailer                | nan      |\n",
      "| Truck w/Flatbed        | nan      |\n",
      "| Truck w/Liquid         | nan      |\n",
      "| Crane Truck            | nan      |\n",
      "| Railway Vehicle        | nan      |\n",
      "| Passenger Car          | nan      |\n",
      "| Cargo Car              | nan      |\n",
      "| Flat Car               | nan      |\n",
      "| Tank car               | nan      |\n",
      "| Locomotive             | nan      |\n",
      "| Maritime Vessel        | nan      |\n",
      "| Motorboat              | nan      |\n",
      "| Sailboat               | nan      |\n",
      "| Tugboat                | nan      |\n",
      "| Barge                  | nan      |\n",
      "| Fishing Vessel         | nan      |\n",
      "| Ferry                  | nan      |\n",
      "| Yacht                  | nan      |\n",
      "| Container Ship         | nan      |\n",
      "| Oil Tanker             | nan      |\n",
      "| Engineering Vehicle    | nan      |\n",
      "| Tower crane            | nan      |\n",
      "| Container Crane        | nan      |\n",
      "| Reach Stacker          | nan      |\n",
      "| Straddle Carrier       | nan      |\n",
      "| Mobile Crane           | nan      |\n",
      "| Dump Truck             | nan      |\n",
      "| Haul Truck             | nan      |\n",
      "| Scraper/Tractor        | nan      |\n",
      "| Front loader/Bulldozer | nan      |\n",
      "| Excavator              | nan      |\n",
      "| Cement Mixer           | nan      |\n",
      "| Ground Grader          | nan      |\n",
      "| Hut/Tent               | nan      |\n",
      "| Shed                   | nan      |\n",
      "| Building               | nan      |\n",
      "| Aircraft Hangar        | nan      |\n",
      "| Damaged Building       | nan      |\n",
      "| Facility               | nan      |\n",
      "| Construction Site      | nan      |\n",
      "| Vehicle Lot            | nan      |\n",
      "| Helipad                | nan      |\n",
      "| Storage Tank           | nan      |\n",
      "| Shipping container lot | nan      |\n",
      "| Shipping Container     | nan      |\n",
      "| Pylon                  | nan      |\n",
      "| Tower                  | nan      |\n",
      "+------------------------+----------+\n",
      "mean coco AP@50:  0.80198\n",
      "Epoch #: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 125/125 [08:16<00:00,  3.97s/it, loss=['loss: 0.056', 'loss_classifier: 0.032', 'loss_box_reg: 0.018', 'loss_objectness: 0.003', 'loss_rpn_box_reg: 0.002']]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time 0:20:17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Start training\")\n",
    "start_time = time.time()\n",
    "\n",
    "losses, model = train_and_eval(model,data_loader,data_loader_test,optimizer,scheduler,device,cpu_device,epochs=2)\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
    "print(f\"Training time {total_time_str}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_exp(lr=None,momentum=None,epochs=None):\n",
    "    '''\n",
    "    '''\n",
    "    model = build_frcnn_model(dataset.num_classes)\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.SGD(\n",
    "            model.parameters(),\n",
    "            lr=lr,\n",
    "            momentum=momentum,\n",
    "            weight_decay=1e-4,\n",
    "            nesterov=\"nesterov\",\n",
    "        )\n",
    "\n",
    "    scheduler_cls = WarmupWrapper(MultiStepLR)\n",
    "    scheduler = scheduler_cls(\n",
    "        'linear',  # warmup schedule\n",
    "        100,  # warmup_iters\n",
    "        0.001,  # warmup_ratio\n",
    "        optimizer,\n",
    "        [177429, 236572],  # milestones\n",
    "        0.1,  # gamma\n",
    "    )\n",
    "    print(\"Start training\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    losses, model = train_and_eval(model,data_loader,data_loader_test,optimizer,scheduler,device,cpu_device,epochs=epochs)\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
    "    print(f\"Training time {total_time_str}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">We might also roll our own simple hyperparameter tuning:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hp_grid_search():\n",
    "    for lr in np.logspace(-4, -2, num=10):\n",
    "        for m in np.linspace(0.7, 0.95, num=10):\n",
    "            print(f\"Training model with learning rate {lr} and momentum {m}\")\n",
    "            define_exp(lr=lr,momentum=m,epochs=1)\n",
    "\n",
    "\n",
    "try:\n",
    "    hp_grid_search()\n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What's Missing?\n",
    "\n",
    "<font size=\"4\">This approach works in theory -- we could get a good model, save it, and use it for predictions.  But we're missing a lot from the ideal state:</font>\n",
    "<font size=\"4\">\n",
    "<ul style=\"margin-top: 15px\">\n",
    "  <li style=\"margin-bottom: 10px\">Distributed training</li>\n",
    "  <li style=\"margin-bottom: 10px\">Parallel search</li>\n",
    "  <li style=\"margin-bottom: 10px\">Intelligent checkpointing</li>\n",
    "  <li style=\"margin-bottom: 10px\">Interruptibility and fault tolerance</li>\n",
    "  <li                            >Logging of experiment configurations and results </li>\n",
    "</ul>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6><b>Scaled Experimentation with Determined</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With less work than setting up a limited random search, you can get started with Determined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our First Experiment\n",
    "\n",
    "For our first example, we run a simple single-GPU training job with fixed hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/determined-ai/public_assets/main/images/StartAnExperiment.png\" align=left width=330/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: det experiment create [-h] [-g] [--local] [--template TEMPLATE]\n",
      "                             [--project_id PROJECT_ID] [--config CONFIG]\n",
      "                             [-f | --paused | -t]\n",
      "                             config_file model_def\n",
      "det experiment create: error: argument config_file: can't open 'const.yaml': [Errno 2] No such file or directory: 'const.yaml'\n"
     ]
    }
   ],
   "source": [
    "!det e create const-dist.yaml ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And evaluate its performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_id = <Enter Experiment ID>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = Determined().get_experiment(experiment_id).top_checkpoint()\n",
    "model = checkpoint.load().model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(model, 'test.jpg', 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling up to Distributed Training\n",
    "\n",
    "Determined makes it trivial to move from single-GPU to multi-GPU (and even multi-node) training. Here we'll simply modify the config above to request 8 GPUs instead of 1, and increase the global batch size to increase the data throughput "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat distributed.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!det experiment create distributed.yaml ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/determined-ai/public_assets/main/images/4GPUexperiment.png\" align=left width=530 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Distributed Hyperparameter Tuning\n",
    "\n",
    "By simply building a config file and adapting our code to meet the determined trial interface, we can conduct a sophisticated hyperparamter search.  Instructions for how to configure different types of experiments [can be found in the Determined documentation.](https://docs.determined.ai/latest/how-to/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat search.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create your Experiment\n",
    "\n",
    "Now that you've described your experiment, you'll simply need to use the command line interface to submit it to the Determined Cluster.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!det experiment create search.yaml ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/determined-ai/public_assets/main/images/12GPUexperiment.png\" align=left width=800 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Registry\n",
    "\n",
    "After training, we'll want to actually use our model in some sort of system.  Determined provides a model registry to version your trained models, making them easy to retrieve for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_id = <Enter Experiment ID>\n",
    "MODEL_NAME = \"pedestrian-detection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best checkpoint from the training\n",
    "checkpoint = Determined().get_experiment(experiment_id).top_checkpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = check_model(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.register_version(checkpoint.uuid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference\n",
    "\n",
    "Once your model is versioned in the model registry, using that model for inference is straightforward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve latest checkpoint for a given model name\n",
    "latest_version = model.get_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model checkpoint into memory\n",
    "inference_model = latest_version.checkpoint.load().model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference as before\n",
    "predict(inference_model, 'test.jpg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
