# name: resnet_fpn_fcos_coco_dist_warmup_2_agents
name: resnet_fpn_frcnn_xview_dist_warmup
profiling:
 enabled: true
 begin_on_batch: 0
 end_after_batch: null
hyperparameters:
    # These settings match that for the 150 epoch run provided in the original repo:
    #   https://github.com/facebookresearch/detr
    lr: 0.01
    # lr: 0.02
    momentum: 0.9
    # global_batch_size: 32
    global_batch_size: 16
    weight_decay: 1.0e-4
    gamma: 0.1
    warmup: linear
    warmup_iters: 200
    warmup_ratio: 0.001
    # step1: 3864 # 3 epochs: 3*1288 == 3864, 
    # step2: 5152 # 4 epochs: 4*1288 == 5152
    step1: 18032 # 14 epochs: 14*1288 == 18,032
    step2: 19320 # 15 epochs: 15*1288 == 19,320
    # step1: 946288 # 16 epochs: 16*59143 == 946,288
    # step2: 1301146 # 22 epochs: 22*59143 == 1,301,146
    # model: mv3_fcos
    model:
      type: categorical
      vals: ['fasterrcnn_resnet50_fpn','fcos_resnet50_fpn', 'ssd300_vgg16','ssdlite320_mobilenet_v3_large','resnet152_fasterrcnn_model','efficientnet_b4_fasterrcnn_model','convnext_large_fasterrcnn_model','convnext_small_fasterrcnn_model']
    
    # fasterrcnn_resnet50_fpn
    # model: fcos_resnet50_fpn
    # model: mobileone_fpn
    # model: ssd300_vgg16
    # model: ssdlite320_mobilenet_v3_large
    # Dataset
    dataset_file: coco
    backend: aws # specifiy the backend you want to use.  one of: gcs, aws, fake, local
    data_dir: determined-ai-coco-dataset # bucket name if using gcs or aws, otherwise directory to dataset
    masks: false
    num_workers: 4

    device: cuda
environment:
    environment_variables:                                                                          
        - NCCL_DEBUG=INFO                                                                           
        # You may need to modify this to match your network configuration.                          
        - NCCL_SOCKET_IFNAME=ens,eth,ib
bind_mounts:
    - host_path: /tmp
      container_path: /data
      read_only: false
scheduling_unit: 400
# scheduling_unit: 40
min_validation_period:
    # epochs: 1
    # batches: 59143
    batches: 1288 # For Real training
    # batches: 100 # for testing
    # batches: 5000
searcher:
  name: grid
  metric: mAP
  smaller_is_better: false
  max_length:
      # epochs: 26
    #   batches: 1537718 # 26*59143 == 1,537,718
    # batches: 59143
    # batches: 38640 # 30*1288 == 38640# Real Training
    batches: 51520 # 50*1288 == 51520# Real Training
    # batches: 100
  # max_trials: 4

records_per_epoch: 1288
# records_per_epoch: 1600
resources:
    # slots_per_trial: 16
    slots_per_trial: 1
    shm_size: 2000000000
max_restarts: 0
# environment:
#   image:
#     gpu: determinedai/model-hub-mmdetection:0.19.0-dev0
#   environment_variables:
#     - OMP_NUM_THREADS=1 # Following pytorch dtrain, this environment variable is set to 1 to avoid overloading the system.
# master_host: 192.168.0.13
# entrypoint: model_def:ObjectDetectionTrial # for testing locally
entrypoint: python3 -m determined.launch.torch_distributed --trial model_def:ObjectDetectionTrial
